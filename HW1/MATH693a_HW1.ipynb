{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import linalg as LA\n",
    "import time\n",
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**MATH693a**\n",
    "\n",
    "**Dr. Peter Blomgren**\n",
    "\n",
    "**Homework 1**\n",
    "\n",
    "**Matteo Polimeno**\n",
    "\n",
    "**Due Date: 09/19/2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rosenbrock Function is given by\n",
    "\n",
    "\\begin{align}\n",
    "f(x) = 100(x_{2}-x_{1}^{2})^{2}+(1-x_{1})^{2}\n",
    "\\end{align}\n",
    "\n",
    "We can easily define this function in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rb(x):\n",
    "    rb = 100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "    return rb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its gradient can easily be found by computing the first derivative with respect to $x_{1}$ and $x_{2}$. For $f^{\\prime}(x_{1})$ we have\n",
    "\n",
    "\\begin{align}\n",
    "f^{\\prime}(x_{1}) = 100(4x_{1}^{3}-4x_{2}x{1})+2x_{1}-2\\\\\n",
    "= 100(4x_{1}^3-4x_{2}x_{1})+2(x_{1}-1)\\\\\n",
    "= 400x_{1}(x_{1}^{2}-x_{2})+2(x_{1}-1);\n",
    "\\end{align}\n",
    "\n",
    "and for $f^{\\prime}(x_{2})$\n",
    "\n",
    "\\begin{align}\n",
    "f^{\\prime}(x_{2}) = 100(2x_{2}-2x_{1}^2)\\\\\n",
    "= 200(x_{2}-x_{1}^{2}).\n",
    "\\end{align}\n",
    "\n",
    "Therefore, the gradient of the Rosenbrock Function is given by\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla{f(x)} ~= ~<400x_{1}(x_{1}^{2}-x_{2})+2(x_{1}-1),~200(x_{2}-x_{1}^{2})>.\n",
    "\\end{align}\n",
    "\n",
    "In order to find the minimum, we need to set the gradient equal to zero\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla{f(x)} = 0\n",
    "\\end{align}\n",
    "\n",
    "for which it holds\n",
    "\n",
    "\\begin{align}\n",
    "(x_{1},x_{2}) = (1,1)\n",
    "\\end{align}\n",
    "\n",
    "As for the Hessian, we have\n",
    "\n",
    "\\begin{align}\n",
    "f_{x_{1}x_{1}} = 1200x_{1}^{2}-400x_{2}^{2}+2~;\\\\\n",
    "\\\n",
    "f_{x_{1}x_{2}} = -400x_{1} = f_{x_{2}x_{1}}~;\\\\\n",
    "\\\n",
    "f_{x_{2}x_{2}} = 200\\\\\n",
    "\\end{align}\n",
    "\n",
    "Thus the Hessian is\n",
    "\n",
    "\\begin{bmatrix}\n",
    "1200x_{1}^{2}-400x_{2}+2 & -400x_{1}\\\\\n",
    "-400x_{1} & 200\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "We can easily define the gradient and the Hessian in Python and then use them to apply the steepest descent and the Newton method for the backline search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rb_grad(x):\n",
    "    df1 = 400*x[0]*(x[0]**2-x[1])+2*(x[0]-1)\n",
    "    df2 = 200*(x[1]-x[0]**2)\n",
    "    grad = np.array([df1,df2])\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess(x):\n",
    "    h11 = 1200*x[0]**2-400*x[1]+2\n",
    "    h12 = -400*x[0]\n",
    "    h21 = -400*x[0]\n",
    "    h22 = 200\n",
    "    hess = np.array([[h11,h12],[h21,h22]])\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invhess(x):\n",
    "    invhess = LA.solve(hess(x),rb_grad(x))\n",
    "    return invhess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rb_back_line_search(x,method):\n",
    "    alpha_bar = 1.\n",
    "    iiter = 1\n",
    "    max_iter = 100000\n",
    "    tol = 1e-8\n",
    "    c1 = 1e-4\n",
    "    rho = .5\n",
    "    alphavals = []\n",
    "    pvals = []\n",
    "    start = time.time()\n",
    "    while LA.norm(rb_grad(x)) > tol and iiter < max_iter:\n",
    "        iiter = iiter + 1\n",
    "        alpha = alpha_bar\n",
    "        if method=='Newton':\n",
    "            p = -invhess(x) #search direction for Newton method\n",
    "        else:\n",
    "            p = -rb_grad(x)/(LA.norm(rb_grad(x))) #search direction for steepest descent method\n",
    "        pt = np.transpose(p)\n",
    "        while rb(x+alpha*p) > rb(x)+c1*alpha*(pt).dot(rb_grad(x)):\n",
    "            alpha = rho*alpha\n",
    "        xnew = x + alpha*p\n",
    "        x = xnew\n",
    "        alpha_k = alpha\n",
    "        alphavals.append(alpha_k)\n",
    "        alpha10 = alphavals[0:10]\n",
    "    end = time.time()\n",
    "    print(\"Elapsed time for \" + method + \" method is \" + np.str(end-start))\n",
    "    print(\"Minimum found at \" + np.str(x))\n",
    "    print(\"Value of Rosenbrock Function at minimum is \" + np.str(rb(x)))\n",
    "    print(\"Search direction is p = \" + np.str(p))\n",
    "    print(\"First 10 alpha values found to be \" + np.str(alpha10))\n",
    "    print(\"Number of iterations necessary for convergence is \" + np.str(iiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for steepest descent method is 9.69500017166\n",
      "Minimum found at [1.         1.00000001]\n",
      "Value of Rosenbrock Function at minimum is 7.244209187686237e-18\n",
      "Search direction is p = [ 0.89012922 -0.45570822]\n",
      "First 10 alpha values found to be [0.125, 0.03125, 0.001953125, 0.00048828125, 0.00048828125, 0.00048828125, 0.00048828125, 0.00048828125, 0.00048828125, 0.00048828125]\n",
      "Number of iterations necessary for convergence is 17067\n"
     ]
    }
   ],
   "source": [
    "rb_back_line_search([1.2,1.2],'steepest descent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for steepest descent method is 9.42100000381\n",
      "Minimum found at [1.         0.99999999]\n",
      "Value of Rosenbrock Function at minimum is 7.033102791657379e-18\n",
      "Search direction is p = [ 0.89927774 -0.43737804]\n",
      "First 10 alpha values found to be [0.25, 0.125, 0.0625, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125]\n",
      "Number of iterations necessary for convergence is 17895\n"
     ]
    }
   ],
   "source": [
    "rb_back_line_search([-1.2,1.],'steepest descent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for Newton method is 0.00599980354309\n",
      "Minimum found at [1. 1.]\n",
      "Value of Rosenbrock Function at minimum is 1.088287359901554e-25\n",
      "Search direction is p = [-1.77859130e-07 -3.53202652e-07]\n",
      "First 10 alpha values found to be [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Number of iterations necessary for convergence is 9\n"
     ]
    }
   ],
   "source": [
    "rb_back_line_search([1.2,1.2],'Newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for Newton method is 0.00499987602234\n",
      "Minimum found at [1. 1.]\n",
      "Value of Rosenbrock Function at minimum is 3.743975643139474e-21\n",
      "Search direction is p = [1.11032194e-06 2.49053263e-06]\n",
      "First 10 alpha values found to be [1.0, 0.125, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.5]\n",
      "Number of iterations necessary for convergence is 22\n"
     ]
    }
   ],
   "source": [
    "rb_back_line_search([-1.2,1.],'Newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
